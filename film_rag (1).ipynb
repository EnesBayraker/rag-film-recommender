{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 📦 Hücre 1 – Ortam Kurulumu ve Sürüm Kontrolü\n",
        "\n",
        "Bu adımda proje boyunca kullanacağımız temel kütüphaneler yüklenir ve ortamın doğru şekilde hazırlandığından emin olunur.  \n",
        "Kullanılan kütüphaneler:\n",
        "- **kaggle**: Veri setini Kaggle API üzerinden indirebilmek için  \n",
        "- **sentence-transformers**: Metin embedding modellerini yüklemek için  \n",
        "- **faiss-cpu**: Yüksek hızlı vektör arama ve benzerlik sorgusu için  \n",
        "- **langchain**: Gerekirse RAG pipeline’ını genişletmek için  \n",
        "- **gradio**: Web arayüzü oluşturmak için  \n",
        "\n",
        "Kurulum sonrası, NumPy, Python ve FAISS sürümleri kontrol edilerek ortamın uyumlu olduğu doğrulanır.\n"
      ],
      "metadata": {
        "id": "Ei83RKh0Q1PX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUTJZYWBnIzg"
      },
      "outputs": [],
      "source": [
        "%pip -q install kaggle==1.6.14 sentence-transformers==3.0.1 faiss-cpu==1.12.0 \\\n",
        "                langchain==0.2.14 langchain-community==0.2.12 gradio\n",
        "\n",
        "import numpy as np, pandas as pd, faiss, sys\n",
        "print(\"✅ NumPy:\", np.__version__)\n",
        "print(\"✅ Python:\", sys.version.split()[0])\n",
        "print(\"✅ FAISS:\", faiss.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📂 Hücre 2 – TMDB Film Verisinin İndirilmesi\n",
        "\n",
        "Bu hücrede proje için gerekli olan film verisi **Kaggle** üzerinden çekilir.  \n",
        "İşlemler adım adım şu şekilde yapılır:\n",
        "\n",
        "1. Kullanıcının `kaggle.json` API anahtarını yüklemesi istenir.  \n",
        "2. Anahtar dosyası Colab ortamına yerleştirilip erişim izinleri ayarlanır.  \n",
        "3. TMDB film verileri (`tmdb_5000_movies.csv` ve `tmdb_5000_credits.csv`) Kaggle’dan indirilir ve `/content/` dizinine çıkarılır.  \n",
        "\n",
        "Bu veri seti; film başlığı, özet, tür, oyuncular, yönetmen, yazarlar gibi bilgileri içermekte ve öneri motorunun temel verisini oluşturacaktır.\n"
      ],
      "metadata": {
        "id": "VMcZVca1Q-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, stat\n",
        "\n",
        "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
        "    print(\"👉 'kaggle.json' yükleyin (Kaggle > Account > Create New Token).\")\n",
        "    up = files.upload()\n",
        "    assert 'kaggle.json' in up, \"kaggle.json seçilmedi.\"\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    with open('/root/.kaggle/kaggle.json','wb') as f: f.write(up['kaggle.json'])\n",
        "    os.chmod('/root/.kaggle/kaggle.json', stat.S_IRUSR | stat.S_IWUSR)\n",
        "\n",
        "!kaggle datasets download -d tmdb/tmdb-movie-metadata -p /content -q\n",
        "!unzip -o /content/tmdb-movie-metadata.zip -d /content/ > /dev/null\n",
        "print(\"✅ Veri indirildi:\", os.path.exists(\"/content/tmdb_5000_movies.csv\"),\n",
        "      os.path.exists(\"/content/tmdb_5000_credits.csv\"))\n"
      ],
      "metadata": {
        "id": "s6N02Xlvn-Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧹 Hücre 3 – Veri Setinin Hazırlanması ve Bilgi Zenginleştirme\n",
        "\n",
        "Bu aşamada ham veriler okunur, temizlenir ve modelin anlayabileceği bir yapıya dönüştürülür:\n",
        "\n",
        "- **JSON benzeri sütunlar parse edilir**: türler, anahtar kelimeler, oyuncu kadrosu ve ekip bilgileri Python listelerine çevrilir.\n",
        "- **Temel bilgiler çıkarılır**: yönetmen, yazarlar ve en popüler oyuncular ayrı sütunlara alınır.\n",
        "- **Metin temsili oluşturulur (`doc`)**: her film için özet, tür, anahtar kelime, yönetmen ve oyuncuların birleşiminden oluşan tek bir belge metni oluşturulur. Bu belge embedding için kullanılacaktır.\n",
        "- **Gereksiz sütunlar atılır ve veri temizlenir.**\n",
        "\n",
        "Bu adımın sonunda her film için anlamlı, semantik olarak zengin bir temsil elde edilir ve bu temsil sonraki embedding aşamasında kullanılacaktır.\n"
      ],
      "metadata": {
        "id": "ALV2BffJRDWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, ast\n",
        "\n",
        "movies  = pd.read_csv(\"/content/tmdb_5000_movies.csv\")\n",
        "credits = pd.read_csv(\"/content/tmdb_5000_credits.csv\")\n",
        "\n",
        "def parse_json_like(s):\n",
        "    try: return ast.literal_eval(s) if isinstance(s,str) else []\n",
        "    except: return []\n",
        "\n",
        "movies['genres']   = movies['genres'].apply(parse_json_like)\n",
        "movies['keywords'] = movies['keywords'].apply(parse_json_like)\n",
        "credits['cast']    = credits['cast'].apply(parse_json_like)\n",
        "credits['crew']    = credits['crew'].apply(parse_json_like)\n",
        "\n",
        "df = movies.merge(credits, left_on='id', right_on='movie_id', how='left')\n",
        "\n",
        "# title güvenceye al\n",
        "if 'title' not in df.columns:\n",
        "    if 'title_x' in df.columns: df['title'] = df['title_x']\n",
        "    elif 'title_y' in df.columns: df['title'] = df['title_y']\n",
        "\n",
        "def get_director(crew):\n",
        "    for c in crew or []:\n",
        "        if c.get('job') == 'Director': return c.get('name')\n",
        "    return None\n",
        "\n",
        "def get_writers(crew):\n",
        "    return [c.get('name') for c in (crew or []) if c.get('department')=='Writing'][:3]\n",
        "\n",
        "def top_cast(cast, k=5):\n",
        "    return [c.get('name') for c in (cast or [])][:k]\n",
        "\n",
        "df['director']      = df['crew'].apply(get_director)\n",
        "df['writers']       = df['crew'].apply(get_writers)\n",
        "df['top_cast']      = df['cast'].apply(top_cast)\n",
        "df['genre_names']   = df['genres'].apply(lambda xs: [x.get('name') for x in xs] if isinstance(xs,list) else [])\n",
        "df['keyword_names'] = df['keywords'].apply(lambda xs: [x.get('name') for x in xs] if isinstance(xs,list) else [])\n",
        "\n",
        "def build_doc(row):\n",
        "    parts=[]\n",
        "    if isinstance(row.get('overview'), str) and row['overview'].strip(): parts.append(f\"🎬 Özet: {row['overview']}\")\n",
        "    if row.get('genre_names'): parts.append(f\"📁 Türler: {', '.join(row['genre_names'])}\")\n",
        "    if row.get('keyword_names'): parts.append(f\"✨ Anahtar Kelimeler: {', '.join(row['keyword_names'])}\")\n",
        "    if row.get('director'):    parts.append(f\"🎥 Yönetmen: {row['director']}\")\n",
        "    if row.get('writers'):     parts.append(f\"✍️ Yazarlar: {', '.join(row['writers'])}\")\n",
        "    if row.get('top_cast'):    parts.append(f\"⭐ Oyuncular: {', '.join(row['top_cast'])}\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "df['doc']  = df.apply(build_doc, axis=1)\n",
        "df['year'] = df['release_date'].fillna('').str[:4]\n",
        "\n",
        "keep = ['id','title','year','vote_average','vote_count','popularity','runtime',\n",
        "        'genre_names','top_cast','director','doc']\n",
        "df_clean = df[keep].copy()\n",
        "df_clean = df_clean[df_clean['doc'].str.len()>0].reset_index(drop=True)\n",
        "\n",
        "print(\"✅ Kayıt:\", len(df_clean))\n",
        "df_clean.head(2)\n"
      ],
      "metadata": {
        "id": "JJfT0fA1oBSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 Hücre 4 – Metin Embedding ve FAISS İndeksi Oluşturma\n",
        "\n",
        "Bu hücrede her film belgesi için çok dilli bir embedding oluşturulur ve bu embedding'ler FAISS vektör arama motoruna eklenir.\n",
        "\n",
        "- **SentenceTransformer**: `intfloat/multilingual-e5-small` modeli kullanılarak semantik vektörler oluşturulur.\n",
        "- **Passage formatı**: Belgeler `\"passage: ...\"` formatına dönüştürülerek modele verilir.\n",
        "- **FAISS Index**: Kozinüs benzerliği ile çalışan `IndexFlatIP` yapısı oluşturulur ve embedding'ler burada depolanır.\n",
        "- **Çıktılar kaydedilir**: Hem FAISS indeksi (`movies.index`) hem de meta veriler (`movies.parquet`) diske yazılır.\n",
        "\n",
        "Bu aşama sayesinde sistem, semantik olarak benzer filmleri yüksek hızla bulabilir hale gelir.\n"
      ],
      "metadata": {
        "id": "QBBGYk8GRXHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "MODEL = \"intfloat/multilingual-e5-small\"\n",
        "st = SentenceTransformer(MODEL)\n",
        "\n",
        "def to_passage(x): return \"passage: \" + x\n",
        "\n",
        "texts = df_clean['doc'].tolist()\n",
        "BATCH=128; embs=[]\n",
        "for i in range(0,len(texts),BATCH):\n",
        "    batch = [to_passage(t) for t in texts[i:i+BATCH]]\n",
        "    vecs = st.encode(batch, normalize_embeddings=True, convert_to_numpy=True)\n",
        "    embs.append(vecs)\n",
        "embs = np.vstack(embs).astype('float32')\n",
        "\n",
        "index = faiss.IndexFlatIP(embs.shape[1])\n",
        "index.add(embs)\n",
        "\n",
        "faiss.write_index(index, \"/content/movies.index\")\n",
        "df_clean.to_parquet(\"/content/movies.parquet\", index=False)\n",
        "print(\"✅ Index:\", index.ntotal)\n"
      ],
      "metadata": {
        "id": "VVPu5FBhoFWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔎 Hücre 5 – Sorgu Analizi ve Film Öneri Fonksiyonu\n",
        "\n",
        "Bu bölümde kullanıcıdan gelen doğal dil sorgular işlenir ve en uygun filmler önerilir. Süreç şu adımlarla gerçekleşir:\n",
        "\n",
        "1. **Sorgu türü tespiti**: Kullanıcı benzer film mi yoksa tür/tema bazlı arama mı yapıyor, analiz edilir.\n",
        "2. **Sorgu genişletme (Query Expansion)**:  \n",
        "   - “Movies like …” gibi sorgular için film bilgileri sorguya eklenir.  \n",
        "   - Tür bazlı sorgular için ilgili tematik anahtar kelimeler eklenir.\n",
        "3. **Embedding arama**: Sorgu embedding’i oluşturularak FAISS üzerinde benzer filmler aranır.\n",
        "4. **Filtreleme**:  \n",
        "   - IMDb puanı filtresi  \n",
        "   - Tür filtresi  \n",
        "   - Tematik kelime filtresi\n",
        "5. **Hibrit skor hesaplama**:  \n",
        "   - 0.6: semantik benzerlik  \n",
        "   - 0.3: IMDb puanı  \n",
        "   - 0.1: popülerlik  \n",
        "6. **Sonuçların formatlanması**: En alakalı filmler başlık, yıl, puan, tür ve kısa özetle birlikte döndürülür.\n",
        "\n",
        "Bu fonksiyon, hem semantik anlamı hem de kaliteyi gözeterek kullanıcıya en uygun film önerilerini sunar.\n"
      ],
      "metadata": {
        "id": "9tWbIN9cRew2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "st = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
        "index = faiss.read_index(\"/content/movies.index\")\n",
        "meta  = pd.read_parquet(\"/content/movies.parquet\")\n",
        "\n",
        "def semantic_search(query, k=50):\n",
        "    q = st.encode([\"query: \"+query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n",
        "    D, I = index.search(q, k)\n",
        "    return I[0], D[0]\n",
        "\n",
        "def suggest_movies(query, topn=5, min_rating=6.5, genre=None):\n",
        "    q_lower = query.lower().strip()\n",
        "    expanded_query = query\n",
        "\n",
        "    # 🧠 1️⃣ Sorgu tipi tespiti (benzer film mi yoksa tür temelli mi?)\n",
        "    is_similarity_query = any(phrase in q_lower for phrase in [\"movies like\", \"similar\", \"like \", \"benzeri\", \"gibi\"])\n",
        "\n",
        "    # 🧠 2️⃣ Query expansion (sadece \"movies like\" türü sorgular için)\n",
        "    if is_similarity_query:\n",
        "        matches = meta[meta['title'].str.lower().apply(lambda x: x in q_lower or x in q_lower.replace(\"movies like\", \"\"))]\n",
        "        if len(matches) == 0:\n",
        "            matches = meta[meta['title'].str.lower().apply(lambda x: any(word in q_lower for word in x.split()))]\n",
        "        if len(matches) > 0:\n",
        "            doc_text = matches.iloc[0]['doc']\n",
        "            expanded_query += \" \" + doc_text\n",
        "        expanded_query += \" similar style, tone, pacing, themes, and narrative elements\"\n",
        "\n",
        "    # 🧠 3️⃣ Tür / tema temelli sorgular için hafif zenginleştirme\n",
        "    else:\n",
        "        if \"romantic\" in q_lower or \"romance\" in q_lower:\n",
        "            expanded_query += \" movies about love, dating, relationships, couples, affection\"\n",
        "        if \"comedy\" in q_lower:\n",
        "            expanded_query += \" funny, humorous, feel-good, light-hearted\"\n",
        "        if \"mystery\" in q_lower:\n",
        "            expanded_query += \" mystery, investigation, secrets, disappearance, plot twist\"\n",
        "        if \"sci-fi\" in q_lower or \"science fiction\" in q_lower:\n",
        "            expanded_query += \" futuristic, space, technology, exploration, dystopia\"\n",
        "        if \"slasher\" in q_lower:\n",
        "            expanded_query += \" killer, gore, violent, serial killer, horror\"\n",
        "\n",
        "    # 🧠 4️⃣ Embedding araması\n",
        "    q = st.encode([\"query: \" + expanded_query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n",
        "    D, I = index.search(q, 100)  # daha fazla aday çek\n",
        "    df = meta.iloc[I[0]].copy()\n",
        "    df['similarity'] = D[0]\n",
        "\n",
        "    # 🧠 5️⃣ Temel filtreler\n",
        "    if min_rating:\n",
        "        df = df[df['vote_average'] >= float(min_rating)]\n",
        "\n",
        "    if genre:\n",
        "        df = df[df['genre_names'].apply(lambda gs: genre.lower() in [g.lower() for g in gs])]\n",
        "\n",
        "    # 🧠 6️⃣ Zorunlu tür filtreleme (romantic, comedy vb. varsa)\n",
        "    if \"romantic\" in q_lower or \"romance\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: any(g.lower() in [\"romance\", \"romantic comedy\"] for g in gs))]\n",
        "    if \"comedy\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"comedy\" in [g.lower() for g in gs])]\n",
        "    if \"horror\" in q_lower or \"slasher\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"horror\" in [g.lower() for g in gs])]\n",
        "    if \"mystery\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"mystery\" in [g.lower() for g in gs] or \"thriller\" in [g.lower() for g in gs])]\n",
        "    if \"sci-fi\" in q_lower or \"science fiction\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"science fiction\" in [g.lower() for g in gs])]\n",
        "\n",
        "    # 🧠 7️⃣ Tematik anahtar kelime filtresi (buraya ekledik ✅)\n",
        "    thematic_keywords = {\n",
        "        \"romantic\": [\"love\", \"relationship\", \"couple\", \"dating\", \"romance\", \"wedding\"],\n",
        "        \"mystery\": [\"mystery\", \"detective\", \"investigation\", \"murder\", \"unsolved\", \"crime\", \"secrets\", \"missing\", \"disappearance\"],\n",
        "        \"slasher\": [\"slasher\", \"killer\", \"serial killer\", \"stab\", \"blood\", \"chainsaw\"],\n",
        "        \"sci-fi\": [\"space\", \"future\", \"ai\", \"robot\", \"time travel\", \"planet\", \"exploration\", \"galaxy\"],\n",
        "        \"thriller\": [\"thriller\", \"suspense\", \"cat and mouse\", \"chase\", \"tension\"],\n",
        "        \"coming-of-age\": [\"teen\", \"high school\", \"youth\", \"growing up\", \"adolescence\"],\n",
        "        \"post-apocalyptic\": [\"apocalypse\", \"end of world\", \"dystopia\", \"survivors\", \"wasteland\"],\n",
        "        \"heist\": [\"robbery\", \"bank\", \"crime crew\", \"plan\", \"steal\"],\n",
        "        \"emotional\": [\"cry\", \"tearjerker\", \"tragic\", \"sad\", \"grief\", \"loss\", \"death\", \"moving\", \"heartbreaking\", \"weep\", \"touching\", \"sentimental\"],\n",
        "\n",
        "    }\n",
        "\n",
        "    for theme, kws in thematic_keywords.items():\n",
        "        if theme in q_lower:\n",
        "            df = df[df['doc'].str.lower().apply(lambda x: any(kw in x for kw in kws))]\n",
        "\n",
        "    # 🧠 8️⃣ Hibrit skor hesaplama\n",
        "    df['score'] = (\n",
        "        0.6 * df['similarity'] +\n",
        "        0.3 * (df['vote_average'] / 10.0) +\n",
        "        0.1 * (df['popularity'] / df['popularity'].max())\n",
        "    )\n",
        "\n",
        "    df = df.sort_values('score', ascending=False).head(topn)\n",
        "\n",
        "    # 🧠 9️⃣ Sonuçları formatla\n",
        "    out = [f\"🎯 Sorgu: {query}\\n\"]\n",
        "    for i, row in df.iterrows():\n",
        "        genres = \", \".join(row['genre_names'])\n",
        "        desc = row['doc'].split(\"\\n\")[0].replace(\"🎬 Özet: \", \"\")[:220] + \"...\"\n",
        "        out.append(f\"{len(out)}. {row['title']} ({row['year']}) — ⭐ {row['vote_average']:.1f}\\n   🎭 {genres}\\n   📖 {desc}\\n\")\n",
        "\n",
        "    return \"\\n\".join(out) if len(out) > 1 else \"Sonuç bulunamadı.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yDFp7gWyr_1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻 Hücre 6 – Web Arayüzü ile Kullanıcı Etkileşimi\n",
        "\n",
        "Son aşamada, film öneri motoru bir web arayüzü üzerinden erişilebilir hale getirilir. Bunun için **Gradio** kullanılır.\n",
        "\n",
        "- Kullanıcıdan alınan parametreler:  \n",
        "  - 🎬 Sorgu (tema veya benzer film araması)  \n",
        "  - 🎭 Tür (opsiyonel)  \n",
        "  - ⭐ Minimum IMDb puanı  \n",
        "  - 📊 Sonuç sayısı  \n",
        "- `suggest_movies` fonksiyonu ile öneriler oluşturulur.  \n",
        "- Sonuçlar, markdown formatında anlaşılır bir şekilde sunulur.\n",
        "\n",
        "`demo.launch(share=True)` ile uygulama paylaşılabilir hale gelir ve web üzerinden test edilebilir.\n",
        "\n",
        "Bu arayüz, projenin ürünleşmiş halini temsil eder ve son kullanıcının kolayca öneriler almasını sağlar.\n"
      ],
      "metadata": {
        "id": "Fr_fCM5JRkhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def recommend_interface(query, genre, min_rating, topn):\n",
        "    genre = (genre or \"\").strip() or None\n",
        "    return suggest_movies(query, topn=int(topn), min_rating=float(min_rating), genre=genre)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"🎬 Film Araması\", placeholder=\"ör: romantik komedi, slasher, duygusal bilim kurgu\"),\n",
        "        gr.Textbox(label=\"🎭 Tür (opsiyonel)\", placeholder=\"ör: Animation, Drama, Horror\"),\n",
        "        gr.Slider(0,10, value=6.5, step=0.1, label=\"⭐ Minimum Puan\"),\n",
        "        gr.Slider(1,15, value=5, step=1, label=\"📊 Kaç film?\")\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"🎞️ Önerilen Filmler\"),\n",
        "    title=\"🎥 RAG Film Öneri\",\n",
        "    description=\"E5 embedding + FAISS ile semantik arama, basit filtreler ve temiz çıktı.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "e_j4StABsG8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}