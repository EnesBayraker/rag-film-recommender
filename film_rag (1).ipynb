{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“¦ HÃ¼cre 1 â€“ Ortam Kurulumu ve SÃ¼rÃ¼m KontrolÃ¼\n",
        "\n",
        "Bu adÄ±mda proje boyunca kullanacaÄŸÄ±mÄ±z temel kÃ¼tÃ¼phaneler yÃ¼klenir ve ortamÄ±n doÄŸru ÅŸekilde hazÄ±rlandÄ±ÄŸÄ±ndan emin olunur.  \n",
        "KullanÄ±lan kÃ¼tÃ¼phaneler:\n",
        "- **kaggle**: Veri setini Kaggle API Ã¼zerinden indirebilmek iÃ§in  \n",
        "- **sentence-transformers**: Metin embedding modellerini yÃ¼klemek iÃ§in  \n",
        "- **faiss-cpu**: YÃ¼ksek hÄ±zlÄ± vektÃ¶r arama ve benzerlik sorgusu iÃ§in  \n",
        "- **langchain**: Gerekirse RAG pipelineâ€™Ä±nÄ± geniÅŸletmek iÃ§in  \n",
        "- **gradio**: Web arayÃ¼zÃ¼ oluÅŸturmak iÃ§in  \n",
        "\n",
        "Kurulum sonrasÄ±, NumPy, Python ve FAISS sÃ¼rÃ¼mleri kontrol edilerek ortamÄ±n uyumlu olduÄŸu doÄŸrulanÄ±r.\n"
      ],
      "metadata": {
        "id": "Ei83RKh0Q1PX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUTJZYWBnIzg"
      },
      "outputs": [],
      "source": [
        "%pip -q install kaggle==1.6.14 sentence-transformers==3.0.1 faiss-cpu==1.12.0 \\\n",
        "                langchain==0.2.14 langchain-community==0.2.12 gradio\n",
        "\n",
        "import numpy as np, pandas as pd, faiss, sys\n",
        "print(\"âœ… NumPy:\", np.__version__)\n",
        "print(\"âœ… Python:\", sys.version.split()[0])\n",
        "print(\"âœ… FAISS:\", faiss.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“‚ HÃ¼cre 2 â€“ TMDB Film Verisinin Ä°ndirilmesi\n",
        "\n",
        "Bu hÃ¼crede proje iÃ§in gerekli olan film verisi **Kaggle** Ã¼zerinden Ã§ekilir.  \n",
        "Ä°ÅŸlemler adÄ±m adÄ±m ÅŸu ÅŸekilde yapÄ±lÄ±r:\n",
        "\n",
        "1. KullanÄ±cÄ±nÄ±n `kaggle.json` API anahtarÄ±nÄ± yÃ¼klemesi istenir.  \n",
        "2. Anahtar dosyasÄ± Colab ortamÄ±na yerleÅŸtirilip eriÅŸim izinleri ayarlanÄ±r.  \n",
        "3. TMDB film verileri (`tmdb_5000_movies.csv` ve `tmdb_5000_credits.csv`) Kaggleâ€™dan indirilir ve `/content/` dizinine Ã§Ä±karÄ±lÄ±r.  \n",
        "\n",
        "Bu veri seti; film baÅŸlÄ±ÄŸÄ±, Ã¶zet, tÃ¼r, oyuncular, yÃ¶netmen, yazarlar gibi bilgileri iÃ§ermekte ve Ã¶neri motorunun temel verisini oluÅŸturacaktÄ±r.\n"
      ],
      "metadata": {
        "id": "VMcZVca1Q-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, stat\n",
        "\n",
        "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
        "    print(\"ğŸ‘‰ 'kaggle.json' yÃ¼kleyin (Kaggle > Account > Create New Token).\")\n",
        "    up = files.upload()\n",
        "    assert 'kaggle.json' in up, \"kaggle.json seÃ§ilmedi.\"\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    with open('/root/.kaggle/kaggle.json','wb') as f: f.write(up['kaggle.json'])\n",
        "    os.chmod('/root/.kaggle/kaggle.json', stat.S_IRUSR | stat.S_IWUSR)\n",
        "\n",
        "!kaggle datasets download -d tmdb/tmdb-movie-metadata -p /content -q\n",
        "!unzip -o /content/tmdb-movie-metadata.zip -d /content/ > /dev/null\n",
        "print(\"âœ… Veri indirildi:\", os.path.exists(\"/content/tmdb_5000_movies.csv\"),\n",
        "      os.path.exists(\"/content/tmdb_5000_credits.csv\"))\n"
      ],
      "metadata": {
        "id": "s6N02Xlvn-Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§¹ HÃ¼cre 3 â€“ Veri Setinin HazÄ±rlanmasÄ± ve Bilgi ZenginleÅŸtirme\n",
        "\n",
        "Bu aÅŸamada ham veriler okunur, temizlenir ve modelin anlayabileceÄŸi bir yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r:\n",
        "\n",
        "- **JSON benzeri sÃ¼tunlar parse edilir**: tÃ¼rler, anahtar kelimeler, oyuncu kadrosu ve ekip bilgileri Python listelerine Ã§evrilir.\n",
        "- **Temel bilgiler Ã§Ä±karÄ±lÄ±r**: yÃ¶netmen, yazarlar ve en popÃ¼ler oyuncular ayrÄ± sÃ¼tunlara alÄ±nÄ±r.\n",
        "- **Metin temsili oluÅŸturulur (`doc`)**: her film iÃ§in Ã¶zet, tÃ¼r, anahtar kelime, yÃ¶netmen ve oyuncularÄ±n birleÅŸiminden oluÅŸan tek bir belge metni oluÅŸturulur. Bu belge embedding iÃ§in kullanÄ±lacaktÄ±r.\n",
        "- **Gereksiz sÃ¼tunlar atÄ±lÄ±r ve veri temizlenir.**\n",
        "\n",
        "Bu adÄ±mÄ±n sonunda her film iÃ§in anlamlÄ±, semantik olarak zengin bir temsil elde edilir ve bu temsil sonraki embedding aÅŸamasÄ±nda kullanÄ±lacaktÄ±r.\n"
      ],
      "metadata": {
        "id": "ALV2BffJRDWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, ast\n",
        "\n",
        "movies  = pd.read_csv(\"/content/tmdb_5000_movies.csv\")\n",
        "credits = pd.read_csv(\"/content/tmdb_5000_credits.csv\")\n",
        "\n",
        "def parse_json_like(s):\n",
        "    try: return ast.literal_eval(s) if isinstance(s,str) else []\n",
        "    except: return []\n",
        "\n",
        "movies['genres']   = movies['genres'].apply(parse_json_like)\n",
        "movies['keywords'] = movies['keywords'].apply(parse_json_like)\n",
        "credits['cast']    = credits['cast'].apply(parse_json_like)\n",
        "credits['crew']    = credits['crew'].apply(parse_json_like)\n",
        "\n",
        "df = movies.merge(credits, left_on='id', right_on='movie_id', how='left')\n",
        "\n",
        "# title gÃ¼venceye al\n",
        "if 'title' not in df.columns:\n",
        "    if 'title_x' in df.columns: df['title'] = df['title_x']\n",
        "    elif 'title_y' in df.columns: df['title'] = df['title_y']\n",
        "\n",
        "def get_director(crew):\n",
        "    for c in crew or []:\n",
        "        if c.get('job') == 'Director': return c.get('name')\n",
        "    return None\n",
        "\n",
        "def get_writers(crew):\n",
        "    return [c.get('name') for c in (crew or []) if c.get('department')=='Writing'][:3]\n",
        "\n",
        "def top_cast(cast, k=5):\n",
        "    return [c.get('name') for c in (cast or [])][:k]\n",
        "\n",
        "df['director']      = df['crew'].apply(get_director)\n",
        "df['writers']       = df['crew'].apply(get_writers)\n",
        "df['top_cast']      = df['cast'].apply(top_cast)\n",
        "df['genre_names']   = df['genres'].apply(lambda xs: [x.get('name') for x in xs] if isinstance(xs,list) else [])\n",
        "df['keyword_names'] = df['keywords'].apply(lambda xs: [x.get('name') for x in xs] if isinstance(xs,list) else [])\n",
        "\n",
        "def build_doc(row):\n",
        "    parts=[]\n",
        "    if isinstance(row.get('overview'), str) and row['overview'].strip(): parts.append(f\"ğŸ¬ Ã–zet: {row['overview']}\")\n",
        "    if row.get('genre_names'): parts.append(f\"ğŸ“ TÃ¼rler: {', '.join(row['genre_names'])}\")\n",
        "    if row.get('keyword_names'): parts.append(f\"âœ¨ Anahtar Kelimeler: {', '.join(row['keyword_names'])}\")\n",
        "    if row.get('director'):    parts.append(f\"ğŸ¥ YÃ¶netmen: {row['director']}\")\n",
        "    if row.get('writers'):     parts.append(f\"âœï¸ Yazarlar: {', '.join(row['writers'])}\")\n",
        "    if row.get('top_cast'):    parts.append(f\"â­ Oyuncular: {', '.join(row['top_cast'])}\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "df['doc']  = df.apply(build_doc, axis=1)\n",
        "df['year'] = df['release_date'].fillna('').str[:4]\n",
        "\n",
        "keep = ['id','title','year','vote_average','vote_count','popularity','runtime',\n",
        "        'genre_names','top_cast','director','doc']\n",
        "df_clean = df[keep].copy()\n",
        "df_clean = df_clean[df_clean['doc'].str.len()>0].reset_index(drop=True)\n",
        "\n",
        "print(\"âœ… KayÄ±t:\", len(df_clean))\n",
        "df_clean.head(2)\n"
      ],
      "metadata": {
        "id": "JJfT0fA1oBSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§  HÃ¼cre 4 â€“ Metin Embedding ve FAISS Ä°ndeksi OluÅŸturma\n",
        "\n",
        "Bu hÃ¼crede her film belgesi iÃ§in Ã§ok dilli bir embedding oluÅŸturulur ve bu embedding'ler FAISS vektÃ¶r arama motoruna eklenir.\n",
        "\n",
        "- **SentenceTransformer**: `intfloat/multilingual-e5-small` modeli kullanÄ±larak semantik vektÃ¶rler oluÅŸturulur.\n",
        "- **Passage formatÄ±**: Belgeler `\"passage: ...\"` formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek modele verilir.\n",
        "- **FAISS Index**: KozinÃ¼s benzerliÄŸi ile Ã§alÄ±ÅŸan `IndexFlatIP` yapÄ±sÄ± oluÅŸturulur ve embedding'ler burada depolanÄ±r.\n",
        "- **Ã‡Ä±ktÄ±lar kaydedilir**: Hem FAISS indeksi (`movies.index`) hem de meta veriler (`movies.parquet`) diske yazÄ±lÄ±r.\n",
        "\n",
        "Bu aÅŸama sayesinde sistem, semantik olarak benzer filmleri yÃ¼ksek hÄ±zla bulabilir hale gelir.\n"
      ],
      "metadata": {
        "id": "QBBGYk8GRXHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "MODEL = \"intfloat/multilingual-e5-small\"\n",
        "st = SentenceTransformer(MODEL)\n",
        "\n",
        "def to_passage(x): return \"passage: \" + x\n",
        "\n",
        "texts = df_clean['doc'].tolist()\n",
        "BATCH=128; embs=[]\n",
        "for i in range(0,len(texts),BATCH):\n",
        "    batch = [to_passage(t) for t in texts[i:i+BATCH]]\n",
        "    vecs = st.encode(batch, normalize_embeddings=True, convert_to_numpy=True)\n",
        "    embs.append(vecs)\n",
        "embs = np.vstack(embs).astype('float32')\n",
        "\n",
        "index = faiss.IndexFlatIP(embs.shape[1])\n",
        "index.add(embs)\n",
        "\n",
        "faiss.write_index(index, \"/content/movies.index\")\n",
        "df_clean.to_parquet(\"/content/movies.parquet\", index=False)\n",
        "print(\"âœ… Index:\", index.ntotal)\n"
      ],
      "metadata": {
        "id": "VVPu5FBhoFWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” HÃ¼cre 5 â€“ Sorgu Analizi ve Film Ã–neri Fonksiyonu\n",
        "\n",
        "Bu bÃ¶lÃ¼mde kullanÄ±cÄ±dan gelen doÄŸal dil sorgular iÅŸlenir ve en uygun filmler Ã¶nerilir. SÃ¼reÃ§ ÅŸu adÄ±mlarla gerÃ§ekleÅŸir:\n",
        "\n",
        "1. **Sorgu tÃ¼rÃ¼ tespiti**: KullanÄ±cÄ± benzer film mi yoksa tÃ¼r/tema bazlÄ± arama mÄ± yapÄ±yor, analiz edilir.\n",
        "2. **Sorgu geniÅŸletme (Query Expansion)**:  \n",
        "   - â€œMovies like â€¦â€ gibi sorgular iÃ§in film bilgileri sorguya eklenir.  \n",
        "   - TÃ¼r bazlÄ± sorgular iÃ§in ilgili tematik anahtar kelimeler eklenir.\n",
        "3. **Embedding arama**: Sorgu embeddingâ€™i oluÅŸturularak FAISS Ã¼zerinde benzer filmler aranÄ±r.\n",
        "4. **Filtreleme**:  \n",
        "   - IMDb puanÄ± filtresi  \n",
        "   - TÃ¼r filtresi  \n",
        "   - Tematik kelime filtresi\n",
        "5. **Hibrit skor hesaplama**:  \n",
        "   - 0.6: semantik benzerlik  \n",
        "   - 0.3: IMDb puanÄ±  \n",
        "   - 0.1: popÃ¼lerlik  \n",
        "6. **SonuÃ§larÄ±n formatlanmasÄ±**: En alakalÄ± filmler baÅŸlÄ±k, yÄ±l, puan, tÃ¼r ve kÄ±sa Ã¶zetle birlikte dÃ¶ndÃ¼rÃ¼lÃ¼r.\n",
        "\n",
        "Bu fonksiyon, hem semantik anlamÄ± hem de kaliteyi gÃ¶zeterek kullanÄ±cÄ±ya en uygun film Ã¶nerilerini sunar.\n"
      ],
      "metadata": {
        "id": "9tWbIN9cRew2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "st = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
        "index = faiss.read_index(\"/content/movies.index\")\n",
        "meta  = pd.read_parquet(\"/content/movies.parquet\")\n",
        "\n",
        "def semantic_search(query, k=50):\n",
        "    q = st.encode([\"query: \"+query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n",
        "    D, I = index.search(q, k)\n",
        "    return I[0], D[0]\n",
        "\n",
        "def suggest_movies(query, topn=5, min_rating=6.5, genre=None):\n",
        "    q_lower = query.lower().strip()\n",
        "    expanded_query = query\n",
        "\n",
        "    # ğŸ§  1ï¸âƒ£ Sorgu tipi tespiti (benzer film mi yoksa tÃ¼r temelli mi?)\n",
        "    is_similarity_query = any(phrase in q_lower for phrase in [\"movies like\", \"similar\", \"like \", \"benzeri\", \"gibi\"])\n",
        "\n",
        "    # ğŸ§  2ï¸âƒ£ Query expansion (sadece \"movies like\" tÃ¼rÃ¼ sorgular iÃ§in)\n",
        "    if is_similarity_query:\n",
        "        matches = meta[meta['title'].str.lower().apply(lambda x: x in q_lower or x in q_lower.replace(\"movies like\", \"\"))]\n",
        "        if len(matches) == 0:\n",
        "            matches = meta[meta['title'].str.lower().apply(lambda x: any(word in q_lower for word in x.split()))]\n",
        "        if len(matches) > 0:\n",
        "            doc_text = matches.iloc[0]['doc']\n",
        "            expanded_query += \" \" + doc_text\n",
        "        expanded_query += \" similar style, tone, pacing, themes, and narrative elements\"\n",
        "\n",
        "    # ğŸ§  3ï¸âƒ£ TÃ¼r / tema temelli sorgular iÃ§in hafif zenginleÅŸtirme\n",
        "    else:\n",
        "        if \"romantic\" in q_lower or \"romance\" in q_lower:\n",
        "            expanded_query += \" movies about love, dating, relationships, couples, affection\"\n",
        "        if \"comedy\" in q_lower:\n",
        "            expanded_query += \" funny, humorous, feel-good, light-hearted\"\n",
        "        if \"mystery\" in q_lower:\n",
        "            expanded_query += \" mystery, investigation, secrets, disappearance, plot twist\"\n",
        "        if \"sci-fi\" in q_lower or \"science fiction\" in q_lower:\n",
        "            expanded_query += \" futuristic, space, technology, exploration, dystopia\"\n",
        "        if \"slasher\" in q_lower:\n",
        "            expanded_query += \" killer, gore, violent, serial killer, horror\"\n",
        "\n",
        "    # ğŸ§  4ï¸âƒ£ Embedding aramasÄ±\n",
        "    q = st.encode([\"query: \" + expanded_query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n",
        "    D, I = index.search(q, 100)  # daha fazla aday Ã§ek\n",
        "    df = meta.iloc[I[0]].copy()\n",
        "    df['similarity'] = D[0]\n",
        "\n",
        "    # ğŸ§  5ï¸âƒ£ Temel filtreler\n",
        "    if min_rating:\n",
        "        df = df[df['vote_average'] >= float(min_rating)]\n",
        "\n",
        "    if genre:\n",
        "        df = df[df['genre_names'].apply(lambda gs: genre.lower() in [g.lower() for g in gs])]\n",
        "\n",
        "    # ğŸ§  6ï¸âƒ£ Zorunlu tÃ¼r filtreleme (romantic, comedy vb. varsa)\n",
        "    if \"romantic\" in q_lower or \"romance\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: any(g.lower() in [\"romance\", \"romantic comedy\"] for g in gs))]\n",
        "    if \"comedy\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"comedy\" in [g.lower() for g in gs])]\n",
        "    if \"horror\" in q_lower or \"slasher\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"horror\" in [g.lower() for g in gs])]\n",
        "    if \"mystery\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"mystery\" in [g.lower() for g in gs] or \"thriller\" in [g.lower() for g in gs])]\n",
        "    if \"sci-fi\" in q_lower or \"science fiction\" in q_lower:\n",
        "        df = df[df['genre_names'].apply(lambda gs: \"science fiction\" in [g.lower() for g in gs])]\n",
        "\n",
        "    # ğŸ§  7ï¸âƒ£ Tematik anahtar kelime filtresi (buraya ekledik âœ…)\n",
        "    thematic_keywords = {\n",
        "        \"romantic\": [\"love\", \"relationship\", \"couple\", \"dating\", \"romance\", \"wedding\"],\n",
        "        \"mystery\": [\"mystery\", \"detective\", \"investigation\", \"murder\", \"unsolved\", \"crime\", \"secrets\", \"missing\", \"disappearance\"],\n",
        "        \"slasher\": [\"slasher\", \"killer\", \"serial killer\", \"stab\", \"blood\", \"chainsaw\"],\n",
        "        \"sci-fi\": [\"space\", \"future\", \"ai\", \"robot\", \"time travel\", \"planet\", \"exploration\", \"galaxy\"],\n",
        "        \"thriller\": [\"thriller\", \"suspense\", \"cat and mouse\", \"chase\", \"tension\"],\n",
        "        \"coming-of-age\": [\"teen\", \"high school\", \"youth\", \"growing up\", \"adolescence\"],\n",
        "        \"post-apocalyptic\": [\"apocalypse\", \"end of world\", \"dystopia\", \"survivors\", \"wasteland\"],\n",
        "        \"heist\": [\"robbery\", \"bank\", \"crime crew\", \"plan\", \"steal\"],\n",
        "        \"emotional\": [\"cry\", \"tearjerker\", \"tragic\", \"sad\", \"grief\", \"loss\", \"death\", \"moving\", \"heartbreaking\", \"weep\", \"touching\", \"sentimental\"],\n",
        "\n",
        "    }\n",
        "\n",
        "    for theme, kws in thematic_keywords.items():\n",
        "        if theme in q_lower:\n",
        "            df = df[df['doc'].str.lower().apply(lambda x: any(kw in x for kw in kws))]\n",
        "\n",
        "    # ğŸ§  8ï¸âƒ£ Hibrit skor hesaplama\n",
        "    df['score'] = (\n",
        "        0.6 * df['similarity'] +\n",
        "        0.3 * (df['vote_average'] / 10.0) +\n",
        "        0.1 * (df['popularity'] / df['popularity'].max())\n",
        "    )\n",
        "\n",
        "    df = df.sort_values('score', ascending=False).head(topn)\n",
        "\n",
        "    # ğŸ§  9ï¸âƒ£ SonuÃ§larÄ± formatla\n",
        "    out = [f\"ğŸ¯ Sorgu: {query}\\n\"]\n",
        "    for i, row in df.iterrows():\n",
        "        genres = \", \".join(row['genre_names'])\n",
        "        desc = row['doc'].split(\"\\n\")[0].replace(\"ğŸ¬ Ã–zet: \", \"\")[:220] + \"...\"\n",
        "        out.append(f\"{len(out)}. {row['title']} ({row['year']}) â€” â­ {row['vote_average']:.1f}\\n   ğŸ­ {genres}\\n   ğŸ“– {desc}\\n\")\n",
        "\n",
        "    return \"\\n\".join(out) if len(out) > 1 else \"SonuÃ§ bulunamadÄ±.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yDFp7gWyr_1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ’» HÃ¼cre 6 â€“ Web ArayÃ¼zÃ¼ ile KullanÄ±cÄ± EtkileÅŸimi\n",
        "\n",
        "Son aÅŸamada, film Ã¶neri motoru bir web arayÃ¼zÃ¼ Ã¼zerinden eriÅŸilebilir hale getirilir. Bunun iÃ§in **Gradio** kullanÄ±lÄ±r.\n",
        "\n",
        "- KullanÄ±cÄ±dan alÄ±nan parametreler:  \n",
        "  - ğŸ¬ Sorgu (tema veya benzer film aramasÄ±)  \n",
        "  - ğŸ­ TÃ¼r (opsiyonel)  \n",
        "  - â­ Minimum IMDb puanÄ±  \n",
        "  - ğŸ“Š SonuÃ§ sayÄ±sÄ±  \n",
        "- `suggest_movies` fonksiyonu ile Ã¶neriler oluÅŸturulur.  \n",
        "- SonuÃ§lar, markdown formatÄ±nda anlaÅŸÄ±lÄ±r bir ÅŸekilde sunulur.\n",
        "\n",
        "`demo.launch(share=True)` ile uygulama paylaÅŸÄ±labilir hale gelir ve web Ã¼zerinden test edilebilir.\n",
        "\n",
        "Bu arayÃ¼z, projenin Ã¼rÃ¼nleÅŸmiÅŸ halini temsil eder ve son kullanÄ±cÄ±nÄ±n kolayca Ã¶neriler almasÄ±nÄ± saÄŸlar.\n"
      ],
      "metadata": {
        "id": "Fr_fCM5JRkhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def recommend_interface(query, genre, min_rating, topn):\n",
        "    genre = (genre or \"\").strip() or None\n",
        "    return suggest_movies(query, topn=int(topn), min_rating=float(min_rating), genre=genre)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"ğŸ¬ Film AramasÄ±\", placeholder=\"Ã¶r: romantik komedi, slasher, duygusal bilim kurgu\"),\n",
        "        gr.Textbox(label=\"ğŸ­ TÃ¼r (opsiyonel)\", placeholder=\"Ã¶r: Animation, Drama, Horror\"),\n",
        "        gr.Slider(0,10, value=6.5, step=0.1, label=\"â­ Minimum Puan\"),\n",
        "        gr.Slider(1,15, value=5, step=1, label=\"ğŸ“Š KaÃ§ film?\")\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"ğŸï¸ Ã–nerilen Filmler\"),\n",
        "    title=\"ğŸ¥ RAG Film Ã–neri\",\n",
        "    description=\"E5 embedding + FAISS ile semantik arama, basit filtreler ve temiz Ã§Ä±ktÄ±.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "e_j4StABsG8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}